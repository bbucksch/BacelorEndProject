{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "\n",
    "import holidays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET INDEXES OF DATA SUBSEQUENCES (ONE SUBSEQUENCE INCLUDES LAGGED (X) AND HORIZON (Y) LOADS)\n",
    "\n",
    "def get_subsequence_indexes(in_data_df, window_size, step_size):\n",
    "    # in_data_df = full (or train/test) dataset, window_size = number of lagged values + predicted (horizon) values, step_size = spacing between datapoints\n",
    "\n",
    "    last_index = len(in_data_df)\n",
    "    \n",
    "    subseq_first_idx = 0 # Subsequence start and end index\n",
    "    subseq_last_idx = window_size\n",
    "    \n",
    "    subseq_indexes = []\n",
    "    \n",
    "    while subseq_last_idx <= last_index: # Divide all data into subsequences (and get their indexes)\n",
    "\n",
    "        subseq_indexes.append((subseq_first_idx, subseq_last_idx))\n",
    "        \n",
    "        subseq_first_idx += step_size\n",
    "        subseq_last_idx += step_size\n",
    "\n",
    "    return subseq_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET X,Y DATA SPLIT (EVERY DATAPOINT IS MADE UP OF SUB-SEQUENCE)\n",
    "\n",
    "def get_xy_lagged(subseq_indexes, load_data, horizon_size, lag_size):\n",
    "\n",
    "    for i, idx in enumerate(subseq_indexes):\n",
    "\n",
    "        # Create subsequences\n",
    "        subsequence = load_data[idx[0]:idx[1]] # Flat np array\n",
    "\n",
    "        xi = subsequence[0: lag_size]\n",
    "        yi = subsequence[lag_size: lag_size + horizon_size]\n",
    "\n",
    "        if i == 0: # No existing array to append to\n",
    "            y = np.array([yi]) # Turn y and x into rows, to make an array of arrays\n",
    "            x = np.array([xi])\n",
    "\n",
    "        else:\n",
    "            y = np.concatenate((y, np.array([yi])), axis=0) # shape (datapoints, horizon)\n",
    "            x = np.concatenate((x, np.array([xi])), axis=0) # shape (datapoints, input features)\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET DATETIME FEATURES\n",
    "\n",
    "def create_dt_features(df):\n",
    "    df_c = df.copy()\n",
    "    df_c['Hour'] = df_c.index.hour\n",
    "    df_c['Workday'] = df_c.index.map(lambda x: 0 if (x in holidays.Netherlands() or x.dayofweek in (5,6)) else 1) # 1 if workday, 0 if holiday or weekend\n",
    "    df_c['Dayofweek'] = df_c.index.dayofweek\n",
    "    df_c['Quarter'] = df_c.index.quarter\n",
    "    df_c['Month'] = df_c.index.month\n",
    "    df_c['Dayofyear'] = df_c.index.dayofyear\n",
    "    df_c['Dayofmonth'] = df_c.index.day\n",
    "    return df_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET CYCLICAL ENCODING\n",
    "\n",
    "def cyclical_encoding(df, features):\n",
    "    df_c = df.copy()\n",
    "    \n",
    "    for f in features:\n",
    "        total_values = df_c[f].max() # E.g. total months = 12, starting at 1\n",
    "\n",
    "        if df_c[f].min() == 0: # If first value is 0, total values is 1 more e.g. 24 hours\n",
    "            total_values += 1 \n",
    "\n",
    "        df_c[f + '_cos'] = np.cos(2*np.pi* df_c[f]/ total_values) # Encode into cos and sin values, that way end value is close to start value\n",
    "        df_c[f + '_sin'] = np.sin(2*np.pi* df_c[f]/ total_values)\n",
    "    \n",
    "    return df_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET FORMATTED DATA (IN DATE-TIME) AND TRAIN-TEST SPLIT\n",
    "\n",
    "def date_formatting(bus):\n",
    "\n",
    "    df = pd.read_csv(f\"./data/bus_{bus}_load.csv\")\n",
    "    df.index = pd.to_datetime(df.index, unit='h', origin=pd.Timestamp(\"2018-01-01\"))\n",
    "    df.index.name = \"Time\"\n",
    "    df = create_dt_features(df)\n",
    "    df = cyclical_encoding(df, features=[\"Hour\", \"Dayofweek\", \"Quarter\", \"Month\", \"Dayofyear\", \"Dayofmonth\"])\n",
    "\n",
    "    # training_data = df[df.index < split_date] # Splitting data now will cause it to lose 24 training datapoints and 24*7 test datapoints\n",
    "    # test_data = df[df.index >= split_date]\n",
    "\n",
    "    return df\n",
    "\n",
    "def allbus_date_formatting(bus_init=1, bus_final=28):\n",
    "    \n",
    "    allbus_df = {}\n",
    "\n",
    "    for b in range(bus_init, bus_final + 1):\n",
    "        allbus_df[b] = date_formatting(b)\n",
    "\n",
    "    return allbus_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET X,Y DATA \n",
    "\n",
    "def get_xy(in_data_df, step_size, horizon_size, hyperparameters):\n",
    "\n",
    "    subseq_indexes = get_subsequence_indexes(in_data_df = in_data_df, window_size = hyperparameters[\"lag_size\"] + horizon_size, step_size = step_size)\n",
    "    \n",
    "    lagged_x, y = get_xy_lagged(subseq_indexes=subseq_indexes, load_data=in_data_df[hyperparameters[\"selected_features\"][0]].to_numpy(), \n",
    "                                horizon_size=horizon_size, lag_size=hyperparameters[\"lag_size\"])     \n",
    "    \n",
    "    no_lag_features = in_data_df[hyperparameters[\"selected_features\"][1:]].to_numpy() # Array of features that are not lagged, by rows (each row a timestep)\n",
    "\n",
    "    first_timestep = hyperparameters[\"lag_size\"] # Datapoints start after all lagged values can be obtained\n",
    "    last_timestep = len(in_data_df) - (horizon_size - 1) # Last datapoint until it is possible to obtain all horizon values (horizon_size - 1)\n",
    "\n",
    "    x = np.append(lagged_x, no_lag_features[first_timestep: last_timestep], axis=1) # Append no-lag features to lagged load features\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def get_allbus_xy(allbus_in_data, hyperparameters, bus_init=1, bus_final=28, step_size=1, horizon_size=24):\n",
    "\n",
    "    allbus_x, allbus_y = {}, {}\n",
    "\n",
    "    for b in range(bus_init, bus_final + 1):\n",
    "        allbus_x[b], allbus_y[b] = get_xy(allbus_in_data[b], step_size, horizon_size, hyperparameters)\n",
    "    \n",
    "    return allbus_x, allbus_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET X,Y SPLIT IN TRAIN, TEST\n",
    "\n",
    "def split_train_test(x, y, lag_size, split_date=\"2018-10-16\", train_val_split=0.8): # Timestep 6912\n",
    "\n",
    "    original_timestep = (pd.Timestamp(split_date) - pd.Timestamp(\"2018-01-01 00:00:00\")).total_seconds()/3600 # Get original timestep (hour) from split date\n",
    "    split_timestep = int(original_timestep - lag_size) # Split timestep in the new dataframe (starts at timestep lag_size)\n",
    "    \n",
    "    x_tr = x[:split_timestep]\n",
    "    y_tr = y[:split_timestep]\n",
    "\n",
    "    x_train, x_val = x_tr[:int(train_val_split * len(x_tr))], x_tr[int(train_val_split * len(x_tr)):] # Split in train and validation\n",
    "    y_train, y_val = y_tr[:int(train_val_split * len(y_tr))], y_tr[int(train_val_split * len(y_tr)):]\n",
    "\n",
    "    x_test = x[split_timestep:]\n",
    "    y_test = y[split_timestep:]\n",
    "\n",
    "    return x_train, y_train, x_val, y_val, x_test, y_test\n",
    "\n",
    "\n",
    "def allbus_split_train_test(allbus_x, allbus_y, lag_size, bus_init=1, bus_final=28, split_date=\"2018-10-16\"):\n",
    "\n",
    "    allbus_x_train, allbus_y_train, allbus_x_val, allbus_y_val, allbus_x_test, allbus_y_test = {}, {}, {}, {}, {}, {}\n",
    "\n",
    "    for b in range(bus_init, bus_final + 1):\n",
    "        allbus_x_train[b], allbus_y_train[b], allbus_x_val[b], allbus_y_val[b], allbus_x_test[b], allbus_y_test[b] = \\\n",
    "            split_train_test(allbus_x[b], allbus_y[b], lag_size, split_date)\n",
    "    \n",
    "    return allbus_x_train, allbus_y_train, allbus_x_val, allbus_y_val, allbus_x_test, allbus_y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET AND STORE ALL MODELS FOR ALL BUSSES AND THEIR TRAIN/TEST SCORES\n",
    "\n",
    "def get_model(x_train, y_train, x_val, y_val, x_test, y_test, hyperparameters, score_function):\n",
    "     \n",
    "    model = XGBRegressor(n_estimators=hyperparameters[\"n_estimators\"], max_depth=hyperparameters[\"max_depth\"], subsample=hyperparameters[\"subsample\"], \n",
    "                            gamma=hyperparameters[\"gamma\"], reg_lambda=hyperparameters[\"lambda\"], objective=\"reg:squarederror\", tree_method=\"hist\", \n",
    "                            verbosity=3, learning_rate=hyperparameters[\"learning_rate\"])\n",
    "\n",
    "    trained_model = MultiOutputRegressor(model).fit(X=x_train, y=y_train, verbose=True) # Evaluate on validation data\n",
    "\n",
    "    train_forecasts = trained_model.predict(x_train)\n",
    "    train_score = score_function(y_train, train_forecasts)\n",
    "\n",
    "    valid_forecasts = trained_model.predict(x_val)\n",
    "    valid_score = score_function(y_val, valid_forecasts)\n",
    "\n",
    "    test_forecasts = trained_model.predict(x_test)\n",
    "    test_score = score_function(y_test, test_forecasts)\n",
    "\n",
    "    model_score = {\"Train score\": train_score, \"Validation score\": valid_score, \"Test score\": test_score}\n",
    "\n",
    "    return trained_model, model_score\n",
    "\n",
    "\n",
    "def get_models(models_datapath, hyperparameters, score_function, bus_init=1, bus_final=28, horizon_size=24, step_size=1, \n",
    "               allbus_x_train=None, allbus_y_train=None, allbus_x_val=None, allbus_y_val=None, allbus_x_test=None, allbus_y_test=None):\n",
    "\n",
    "    trained_models = {}\n",
    "    model_scores = {}\n",
    "    \n",
    "    for bus in range(bus_init, bus_final + 1):\n",
    "\n",
    "        if (allbus_x_train != None) and (allbus_y_train != None) and (allbus_x_val != None) and (allbus_y_val != None) and \\\n",
    "            (allbus_x_test != None) and (allbus_y_test != None): # If they're all defined\n",
    "            x_train, y_train, x_val, y_val, x_test, y_test = allbus_x_train[bus], allbus_y_train[bus], allbus_x_val[bus], allbus_y_val[bus], \\\n",
    "                allbus_x_test[bus], allbus_y_test[bus]\n",
    "        \n",
    "        else:\n",
    "            print(\"Missing input data to get_models()\")\n",
    "\n",
    "            df = date_formatting(bus)\n",
    "\n",
    "            x, y = get_xy(df, step_size, horizon_size, hyperparameters)\n",
    "\n",
    "            x_train, y_train, x_val, y_val, x_test, y_test = split_train_test(x, y, hyperparameters[\"lag_size\"])\n",
    "        \n",
    "        \n",
    "        trained_model, model_scores[bus] = get_model(x_train, y_train, x_val, y_val, x_test, y_test, hyperparameters, score_function)\n",
    "        \n",
    "        trained_models[bus] = trained_model\n",
    "\n",
    "        # Store models\n",
    "        with open(f\"{models_datapath}/MOR_bus{bus}.pkl\", \"wb\") as f1:\n",
    "            pickle.dump(trained_model, f1)\n",
    "\n",
    "    # Store model scores\n",
    "    with open(f\"{models_datapath}/MOR_scores.pkl\", \"wb\") as f2:\n",
    "                pickle.dump(model_scores, f2)\n",
    "\n",
    "    return trained_models, model_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET SINGLE-BUS PREDICTION, WITH TIME RELATIVE TO START OF TEST DATA\n",
    "\n",
    "def predict_bus(x_test, y_test, bus, t_init, t_duration, models_datapath, score_function): # Starting at 2018-10-16 00:00:00 by default\n",
    "\n",
    "    # if not (x_test.any() and y_test.any()): # If x_test or y_test are not provided, get it\n",
    "    #     if not test_data.any(): # If test_data is not provided, get it\n",
    "    #         _, _, test_data = date_formatting(bus=bus)\n",
    "\n",
    "    #     x_test, y_test = get_xy(test_data, step_size, horizon_size, hyperparameters)\n",
    "\n",
    "    x = x_test[t_init: t_init + t_duration]\n",
    "    y = y_test[t_init: t_init + t_duration]\n",
    "    \n",
    "    with open(f\"{models_datapath}/MOR_bus{bus}.pkl\", \"rb\") as f1:\n",
    "        model = pickle.load(f1)\n",
    "\n",
    "    with open(f\"{models_datapath}/MOR_scores.pkl\", \"rb\") as f2:\n",
    "        model_scores = pickle.load(f2)\n",
    "\n",
    "    total_model_score = model_scores[bus]\n",
    "\n",
    "    forecast = model.predict(x)\n",
    "    prediction_score = score_function(y, forecast)\n",
    "\n",
    "    return forecast, y, x, prediction_score, total_model_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET PREDICTIONS FOR ALL BUSSES, WITH TIME RELATIVE TO START OF TEST DATA\n",
    "\n",
    "def predict_allbus(allbus_x_test, allbus_y_test, t_init, t_duration, models_datapath, out_path, score_function, bus_init=1, bus_final=28,\n",
    "                   actual_bus_numbers=np.array([None])): # t_init w.r.t. test data start\n",
    "    \n",
    "    # if (allbus_x_test != None) and (allbus_y_test != None): # If allbus_x_test and allbus_y_test are provided, disregard allbus_test_data. Else provide it.\n",
    "    #     allbus_test_data = None\n",
    "\n",
    "    bus_predictions, bus_y_actual, bus_x_actual, bus_prediction_score, model_score = {}, {}, {}, {}, {}\n",
    "\n",
    "    \n",
    "    for bus in range(bus_init, bus_final + 1): # Get individual bus predictions\n",
    "        bus_predictions[bus], bus_y_actual[bus], bus_x_actual[bus], bus_prediction_score[bus], model_score[bus] = predict_bus(allbus_x_test[bus], \n",
    "            allbus_y_test[bus], bus, t_init, t_duration, models_datapath, score_function)\n",
    "\n",
    "    if not actual_bus_numbers.any(): # If actual bus numbers not defined\n",
    "        actual_bus_numbers = np.array([i for i in range(bus_init, bus_final + 1)])\n",
    "    \n",
    "    predictions_df = pd.concat([pd.concat([pd.Series(bus_predictions[b][t]).to_frame().T for b in range(bus_init, bus_final + 1)], \n",
    "                                          axis=0).set_index(actual_bus_numbers) for t in range(t_init, t_init + t_duration)], axis=0) \n",
    "    \n",
    "    # Rows of 24-hour predictions per bus concatenated into pd for every timestep, then pds concatenated for all timesteps\n",
    "\n",
    "    # predictions.set_index(actual_bus_numbers)\n",
    "\n",
    "    predictions_df.to_csv(out_path + \"/forecast.csv\")\n",
    "\n",
    "    return predictions_df, bus_predictions, bus_y_actual, bus_x_actual, bus_prediction_score, model_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE HYPERPARAMETERS AND GET ALL TRAINING AND TESTING X AND Y DATA\n",
    "\n",
    "hyperparameters = {\"lag_size\": 7*24, \"n_estimators\": 100, \"max_depth\": 3, \"subsample\": 1,\n",
    "                   \"selected_features\": [\"Load\", \"Hour_cos\", \"Hour_sin\", \"Workday\"], \n",
    "                   \"learning_rate\": 0.1, \"gamma\": 0, \"lambda\": 1,\n",
    "                   \"early_stopping_rounds\": 10}\n",
    "\n",
    "# n_estimators determines how many rounds of training (how many new trees can be made)\n",
    "# early_stopping_rounds determines how many rounds of training can go before validation set score improves from its best score. Needs validation set \n",
    "#   to be included when training/fitting. If there is any number, the model with iteration that has best score on validation set will be used when \n",
    "#   predicting, even if training is not early stopped. In that case, it will be the same model as changing n_estimators to be the same as best validation iter\n",
    "\n",
    "data_store_path = \"./train_test_data\"\n",
    "\n",
    "# Get train-test split for all busses\n",
    "allbus_df = allbus_date_formatting(bus_init=1, bus_final=28)\n",
    "\n",
    "# Get x,y split for all busses\n",
    "allbus_x, allbus_y = get_allbus_xy(allbus_df, hyperparameters, bus_init=1, bus_final=28, step_size=1, horizon_size=24) \n",
    "# Uses hyperparameters lag_size, selected_features\n",
    "\n",
    "# Get x,y split for all busses test data\n",
    "allbus_x_train, allbus_y_train, allbus_x_val, allbus_y_val, allbus_x_test, allbus_y_test = \\\n",
    "    allbus_split_train_test(allbus_x, allbus_y, hyperparameters[\"lag_size\"], bus_init=1, bus_final=28)\n",
    "\n",
    "# Store the data in a file\n",
    "with open(f\"{data_store_path}/allbus_train_test.pkl\", \"wb\") as f:\n",
    "    pickle.dump((allbus_x_train, allbus_y_train, allbus_x_val, allbus_y_val, allbus_x_test, allbus_y_test), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load back data\n",
    "\n",
    "data_store_path = \"./train_test_data\"\n",
    "\n",
    "with open(f\"{data_store_path}/allbus_train_test.pkl\", \"rb\") as f2:\n",
    "    (allbus_x_train, allbus_y_train, allbus_x_val, allbus_y_val, allbus_x_test, allbus_y_test) = pickle.load(f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allbus_x[1].shape \n",
    "# Should be be [8760 - 24 + 1 (last 23 datapoints can't be used) - 24*7 (first 24*7 datapoints can't be used), \n",
    "# by 24*7=168 lag features + no_lag_features features] = [8569, 168 + no_lag_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN AND STORE THE MODELS FOR ALL BUSSES\n",
    "\n",
    "trained_models, model_scores = get_models(models_datapath=\"./MOR_v1\", hyperparameters=hyperparameters, score_function=mean_absolute_error, \n",
    "                                allbus_x_train=allbus_x_train, allbus_y_train=allbus_y_train, allbus_x_val=allbus_x_val,\n",
    "                                 allbus_y_val=allbus_y_val, allbus_x_test=allbus_x_test, allbus_y_test=allbus_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET BENCHMARK SCORES\n",
    "\n",
    "with open(\"./benchmark_scores.pkl\", \"rb\") as f2:\n",
    "    allbus_benchmarks = pickle.load(f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPARE BENCHMARK AND ACTUAL SCORES\n",
    "\n",
    "score_compare = {}\n",
    "approved_trains = [1 for _ in range(28)]\n",
    "approved_tests = [1 for _ in range(28)]\n",
    "\n",
    "for b in range(1, 29):\n",
    "\n",
    "    train_predict = trained_models[b].predict(allbus_x_train[b])\n",
    "    test_predict = trained_models[b].predict(allbus_x_test[b])\n",
    "\n",
    "    train_score = mean_absolute_error(train_predict, allbus_y_train[b])\n",
    "    test_score = mean_absolute_error(test_predict, allbus_y_test[b])\n",
    "\n",
    "    score_compare[b] = {\"Train\": train_score, \"Test\": test_score}\n",
    "\n",
    "    for t in [1, 24, 24*7]:\n",
    "        if allbus_benchmarks[b][f\"{t}h\"][\"Train\"] <= train_score:\n",
    "            approved_trains[b-1] = 0\n",
    "    \n",
    "        if allbus_benchmarks[b][f\"{t}h\"][\"Test\"] <= test_score:\n",
    "            approved_tests[b-1] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing getting a single bus prediction\n",
    "\n",
    "hyperparameters = {\"lag_size\": 7*24, \"n_estimators\": 20, \"max_depth\": 6, \"subsample\": 0.5, \"min_child_weight\": 1, \"selected_features\": [\"Load\", \"Hour\"], \n",
    "                   \"learning_rate\": 0.2, \"early_stopping_rounds\": 10}\n",
    "\n",
    "y_pred1, y_actual1, x_actual1, mae1, model_score1 = predict_bus(allbus_x_test[1], allbus_y_test[1], bus=1, t_init=0, t_duration=24, models_datapath=\"./MOR_v1\", \n",
    "                                                               score_function=mean_absolute_error)\n",
    "print(f\"Predictions: {y_pred1[0]}\")\n",
    "print(f\"Actual: {y_actual1[0]}\")\n",
    "print(f\"Prediction MAE: {mae1}\")\n",
    "print(f\"Model MAE: {model_score1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_bus_numbers = np.array([2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34])\n",
    "actual_bus_numbers += 1\n",
    "\n",
    "P_df, P, Y, X, P_S, M_S  = predict_allbus(t_init=0, t_duration=48, models_datapath=\"./MOR_v1\", out_path=\"./simulation_input\", \n",
    "                                          hyperparameters=hyperparameters, score_function=mean_absolute_error, allbus_x_test=allbus_x_test, \n",
    "                                          allbus_y_test=allbus_y_test, actual_bus_numbers=actual_bus_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(P_S)\n",
    "print(M_S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(time, forecast: np.array, actual: np.array):\n",
    "    fontsize = 16\n",
    "    plot_df = pd.DataFrame({\"Forecast\" : forecast, \"Real value\" : actual}, index=range(time))\n",
    "\n",
    "    fig = plt.figure(figsize=(20,12))\n",
    "    plt.plot(plot_df.index, plot_df[\"Forecast\"], label=\"Forecast\")\n",
    "    plt.plot(plot_df.index, plot_df[\"Real value\"], label=\"Real value\")\n",
    "\n",
    "    plt.xlabel('Time [h]', fontsize=fontsize)\n",
    "    plt.xticks(fontsize=fontsize)\n",
    "    plt.yticks(fontsize=fontsize)\n",
    "    plt.ylabel(\"Load [MW]\", fontsize=fontsize)\n",
    "    plt.grid(True)\n",
    "    plt.legend(fontsize=fontsize)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fontsize = 16\n",
    "timestep = 24*10\n",
    "plot_df = pd.DataFrame({\"Forecast 0h\" : trained_models[2].predict(allbus_x_test[2])[timestep], \"Real value\" : allbus_y_test[2][48]}, index=range(24))\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(20,12))\n",
    "plt.plot(plot_df.index, plot_df[\"Real value\"], label=\"Real value\")\n",
    "plt.plot(plot_df.index, plot_df[\"Forecast 0h\"], label=\"Forecast 0h\")\n",
    "\n",
    "x = [i for i in range(24)]\n",
    "for time in [4, 8, 12, 16, 20]:\n",
    "    plot_kh = trained_models[2].predict(allbus_x_test[2])[timestep+time][:-time]\n",
    "    plt.plot(x[time:], plot_kh, label=f\"Forecast {time}h\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.xlabel('Time [h]', fontsize=fontsize)\n",
    "plt.xticks(fontsize=fontsize)\n",
    "plt.yticks(fontsize=fontsize)\n",
    "plt.ylabel(\"Load [MW]\", fontsize=fontsize)\n",
    "plt.grid(True)\n",
    "plt.legend(fontsize=fontsize)\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
